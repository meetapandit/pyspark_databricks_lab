# Pyspark using Azure Databricks

The aim of this project was to deep dive into Azure Databricks for uploading raw csv datasets and processing using Pyspark
- 3 files for loand, credit_card transactions and BankAccount details were provided
- Transformed the csv files to format datatypes of columns
- Uploaded the csv to databricks as delta tables to hive metastore
- Read delta tables as Pyspark dataframes and performed transformations and aggregations to gain insights from the datasets
- IPython Notebook is uploaded to source code files

## Screenshots from the IPython notebook

- Read Loan.csv as pyspark dataframe
<p align="center">
  <img src="https://github.com/meetapandit/pyspark_databricks_lab/assets/15186489/de12beed-140b-4bd3-8772-2b15d947f015">
</p>

- Read CreditCard dataset
<p align = "center">
  <img src="https://github.com/meetapandit/pyspark_databricks_lab/assets/15186489/7c244eb9-cb12-4e85-9b7b-91deb6f90e51">
</p>

- Read AccountBalance dataset
<p align = "center">
  <img src="https://github.com/meetapandit/pyspark_databricks_lab/assets/15186489/2aea4cda-f794-4301-b6c2-28338d5e6bf2">
</p>

